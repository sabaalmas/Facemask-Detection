{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "S22_COMP6721_Project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. Imports required modules and sets seeds to 0 (for reproducibility)"
      ],
      "metadata": {
        "id": "75vWTfkkUKwP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports required modules\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, ConfusionMatrixDisplay, confusion_matrix, classification_report\n",
        "import random\n",
        "\n",
        "from PIL import Image\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "\n",
        "random.seed(0)\n",
        "np.random.seed(0)\n",
        "torch.manual_seed(0)"
      ],
      "metadata": {
        "id": "j00jEPOFZGYb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16336acb-841c-473e-c161-fa6cf657dab7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f1ddc889090>"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Sets the device for program execution"
      ],
      "metadata": {
        "id": "9uPIh0GmUuav"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "mkkdGB1YsX_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "REMOVE LATER. Unzips the dataset. Not needed if the uncomprressed \"final_dataset\" folder is present in the same directory as the project notebook"
      ],
      "metadata": {
        "id": "CW-96LCQVRgU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "etzlEYK7YFni"
      },
      "outputs": [],
      "source": [
        "!unzip final_dataset.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Defines a function for preprocessing and loading data for the project"
      ],
      "metadata": {
        "id": "eAuA056AVYcX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def project_data_loader(project_dataset_path=\"./final_dataset\"):\n",
        "  \"\"\"This function gets the project dataset from the provided path. The project \n",
        "  data is divided into training, validation, and testing datasets. Finally, the\n",
        "  DataLoader objects are created for each of the three datasets.\n",
        "\n",
        "  Arguments\n",
        "  ---------\n",
        "  project_dataset_path: str\n",
        "    String representing the path to the project dataset directory\n",
        "\n",
        "  Returns\n",
        "  ---------\n",
        "  train_dataloader: torch.utils.data.DataLoader\n",
        "    DataLoader for training dataset\n",
        "  valid_dataloader: torch.utils.data.DataLoader\n",
        "    DataLoader for validation dataset\n",
        "  test_dataloader: torch.utils.data.DataLoader\n",
        "    DataLoader for testing dataset\n",
        "  \"\"\"\n",
        "\n",
        "  # Defines image transform required for preprocessing\n",
        "  preprocess_transform = transforms.Compose(\n",
        "                   [transforms.Resize((32, 32)),\n",
        "                    transforms.ToTensor(),\n",
        "                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "  \n",
        "  # Loads the project dataset\n",
        "  project_dataset = ImageFolder(root=project_dataset_path,\n",
        "                              transform=preprocess_transform)\n",
        "  \n",
        "  # Defines mappings between classes and labels\n",
        "  project_dataset.class_to_idx = {\"1_cloth_mask\": 0,\n",
        "                                \"2_surgical\": 1,\n",
        "                                \"3_n95\": 2,\n",
        "                                \"4_incorrect_mask\": 3,\n",
        "                                \"5_no_mask\": 4}\n",
        "\n",
        "  label_to_class = {v:k for k,v in project_dataset.class_to_idx.items()}\n",
        "\n",
        "  # Automatically splits the project dataset into training, validation, and testing datasets\n",
        "  tvt_count = len(project_dataset)\n",
        "  tv_count = int(tvt_count * 0.8)\n",
        "  train_valid_data, test_data = random_split(project_dataset, \n",
        "                                             [tv_count, tvt_count - tv_count])\n",
        "  tv_count = len(train_valid_data)\n",
        "  train_count = int(tv_count * 0.8)\n",
        "  train_data, valid_data = random_split(train_valid_data, \n",
        "                                        [train_count, tv_count - train_count])\n",
        "  \n",
        "  # Creates dataloaders for training, validation, and testing data\n",
        "  train_dataloader = DataLoader(train_data, batch_size=64)\n",
        "  valid_dataloader = DataLoader(valid_data, batch_size=64)\n",
        "  test_dataloader = DataLoader(test_data, batch_size=64)\n",
        "\n",
        "  return train_dataloader, valid_dataloader, test_dataloader, label_to_class"
      ],
      "metadata": {
        "id": "5eCE9dCGVeEf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Defines the CNN architecture"
      ],
      "metadata": {
        "id": "v6S1-hmKXZXl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.1 Final architecture: Simple CNN architecture"
      ],
      "metadata": {
        "id": "NY0_FnlHkRNb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class StackedCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(StackedCNN, self).__init__()\n",
        "        \n",
        "        self.conv1 = nn.Conv2d(in_channels=3,\n",
        "                               out_channels=8,\n",
        "                               kernel_size=3,\n",
        "                               padding=3//2)\n",
        "        \n",
        "        self.pool1 = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(in_channels=8,\n",
        "                               out_channels=16,\n",
        "                               kernel_size=3,\n",
        "                               padding=3//2)\n",
        "\n",
        "        self.linear1 = nn.Linear(16 * 8 * 8, 256)\n",
        "        self.linear2 = nn.Linear(256, 64)\n",
        "        self.linear3 = nn.Linear(64, 5)\n",
        "\n",
        "        self.dropout = nn.Dropout(p=0.2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.pool1(F.relu(x))\n",
        "        x = self.pool1(F.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.linear1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.linear2(x))\n",
        "        x = self.linear3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "6FY34dJsXmEV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.2 Variant 1: Pooling layers removed from the final architecture"
      ],
      "metadata": {
        "id": "1773PyNRkZfY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class StackedCNNv1(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(StackedCNNv1, self).__init__()\n",
        "        \n",
        "        self.conv1 = nn.Conv2d(in_channels=3,\n",
        "                               out_channels=8,\n",
        "                               kernel_size=3,\n",
        "                               padding=3//2)\n",
        "        \n",
        "        self.conv2 = nn.Conv2d(in_channels=8,\n",
        "                               out_channels=16,\n",
        "                               kernel_size=3,\n",
        "                               padding=3//2)\n",
        "\n",
        "        self.linear1 = nn.Linear(16384, 256)\n",
        "        self.linear2 = nn.Linear(256, 64)\n",
        "        self.linear3 = nn.Linear(64, 5)\n",
        "\n",
        "        self.dropout = nn.Dropout(p=0.2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.linear1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.linear2(x))\n",
        "        x = self.linear3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "dG-Cc0lnj53q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.3 Variant 2: Different number of convolution layers from the final architecture - 3 convolution layers"
      ],
      "metadata": {
        "id": "8AkJt44xmxzb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class StackedCNNv2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(StackedCNNv2, self).__init__()\n",
        "        \n",
        "        self.conv1 = nn.Conv2d(in_channels=3,\n",
        "                               out_channels=8,\n",
        "                               kernel_size=3,\n",
        "                               padding=3//2)\n",
        "        \n",
        "        self.pool1 = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(in_channels=8,\n",
        "                               out_channels=16,\n",
        "                               kernel_size=3,\n",
        "                               padding=3//2)\n",
        "        \n",
        "        self.conv3 = nn.Conv2d(in_channels=16,\n",
        "                               out_channels=32,\n",
        "                               kernel_size=3,\n",
        "                               padding=3//2)\n",
        "        \n",
        "        self.linear1 = nn.Linear(32 * 4 * 4, 256)\n",
        "        self.linear2 = nn.Linear(256, 64)\n",
        "        self.linear3 = nn.Linear(64, 5)\n",
        "\n",
        "        self.dropout = nn.Dropout(p=0.2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool1(F.relu(self.conv1(x)))\n",
        "        x = self.pool1(F.relu(self.conv2(x)))\n",
        "        x = self.pool1(F.relu(self.conv3(x)))\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.linear1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.linear2(x))\n",
        "        x = self.linear3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "u-lamnaumsky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Defines a function for training the neural network"
      ],
      "metadata": {
        "id": "0Rs79Mq1XyX3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(train_dataloader, valid_dataloader, model, criterion, optimizer, num_epoch=20, title=\"current_model\", save_dir=\"./saved_model\"):\n",
        "\n",
        "  training_losses = list()\n",
        "  validation_losses = list()\n",
        "\n",
        "  prev_loss = np.inf\n",
        "  tolerance = 3\n",
        "  loss_counter = 0\n",
        "\n",
        "  for epoch in range(num_epoch):  # Process the dataset \"num_epoch\" times\n",
        "    model.train()\n",
        "    for i, data in enumerate(train_dataloader, 0):\n",
        "        # \"data\" is a list of [inputs, labels]\n",
        "        # Get the inputs and labels from data\n",
        "        inputs, labels = data\n",
        "\n",
        "        # Setting the device for inputs and labels\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()               # Resets all parameter gradients to zero\n",
        "\n",
        "        outputs = model(inputs)             # Completes a forward pass through the network\n",
        "        loss = criterion(outputs, labels)   # Calculates loss of predictions with respect to tagets\n",
        "        loss.backward()                     # Calculates gradient of loss with respect to all parameters\n",
        "        optimizer.step()                    # Performs optimization step using the calculated gradients\n",
        "\n",
        "    # Prints loss value after every epoch\n",
        "    # print(\"Epoch %03d: Train_loss: %.4f \" %(epoch+1, loss.item()))\n",
        "    training_losses.append(loss.item())\n",
        "\n",
        "    \n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      validation_iterator = iter(valid_dataloader)\n",
        "      valid_inputs, valid_labels = validation_iterator.next()\n",
        "\n",
        "      valid_inputs = valid_inputs.to(device)\n",
        "      valid_labels = valid_labels.to(device)\n",
        "      \n",
        "      valid_outputs = model(valid_inputs)\n",
        "      valid_loss = criterion(valid_outputs, valid_labels)\n",
        "      print(\"Epoch %03d: Train_loss: %.4f, Validation_loss: %.4f \" %(epoch+1, loss.item(), valid_loss.item()))\n",
        "      validation_losses.append(valid_loss.item())\n",
        "\n",
        "    # Stops training before completing the number of epochs if the validation loss gets worse for \"tolerance\" times\n",
        "    if valid_loss > prev_loss:\n",
        "      loss_counter += 1\n",
        "    else:\n",
        "      loss_counter = 0\n",
        "    \n",
        "    if loss_counter >= tolerance:\n",
        "      print(\"Observing increasing values for validation loss. Early stopping.\")\n",
        "      break\n",
        "    \n",
        "    prev_loss = valid_loss\n",
        "\n",
        "  plt.plot(training_losses, label=\"Training loss\")\n",
        "  plt.plot(validation_losses, label=\"Validation loss\")\n",
        "  plt.title(\"Loss vs epoch for \" + title)\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(\"Loss\")\n",
        "  plt.legend(frameon=False)\n",
        "  plt.show()\n",
        "\n",
        "  print(\"Training completed. Saving model.\")\n",
        "  MODEL_SAVE_PATH = save_dir\n",
        "  torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
        "  return MODEL_SAVE_PATH\n"
      ],
      "metadata": {
        "id": "LP765VxNX3xZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Defines a function for loading saved model and testing"
      ],
      "metadata": {
        "id": "bGsZJdZhaPuF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_confusion_matrix(y_preds, y_true, labels, title):\n",
        "    \"\"\"This function displays the confusion matrix for provided predictions by a classifier.\n",
        "\n",
        "    Arguments\n",
        "    ---------\n",
        "    y_preds : numpy.ndarray\n",
        "      Predictions by a classifier\n",
        "    y_true : numpy.ndarray\n",
        "      Labels corresponding to the predictions in y_preds\n",
        "    labels : list\n",
        "      Label names to be used for the confusion matrix\n",
        "    title : str\n",
        "      Title to be used for the confusion matrix\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    cm = confusion_matrix(y_true, y_preds, normalize=\"true\")\n",
        "    fix, ax = plt.subplots(figsize=(6, 6))\n",
        "    cm_display = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
        "    cm_display.plot(cmap=\"Blues\", values_format=\".2f\", ax=ax, colorbar=False)\n",
        "    plt.title(\"Normalized confusion matrix for \" + title)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def print_classification_report(y_preds, y_true, title):\n",
        "    \"\"\"This function displays the classification report for provided predictions by a classifier.\n",
        "\n",
        "    Arguments\n",
        "    ---------\n",
        "    y_preds : numpy.ndarray\n",
        "      Predictions by a classifier\n",
        "    y_true : numpy.ndarray\n",
        "      Labels corresponding to the predictions in y_preds\n",
        "    title : str\n",
        "      Title to be used for the confusion matrix\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    labels = [\"0_cloth\", \"1_surgical\", \"2_n95\", \"3_incorrect\", \"4_no_mask\"]\n",
        "    plot_confusion_matrix(y_preds, y_true, labels, title)\n",
        "    print(\"\\n\")\n",
        "    print(\"Classification report for \" + title)\n",
        "    acc = accuracy_score(y_true, y_preds)\n",
        "    f1 = f1_score(y_true, y_preds, average=\"weighted\")\n",
        "    prec = precision_score(y_true, y_preds, average=\"weighted\")\n",
        "    rec = recall_score(y_true, y_preds, average=\"weighted\")\n",
        "\n",
        "    print(\"-\" * 75)\n",
        "    print(\"Accuracy: %.2f%%\" % (acc * 100))\n",
        "    print(\"Precision: %.2f%%\" % (prec * 100))\n",
        "    print(\"Recall: %.2f%%\" % (rec * 100))\n",
        "    print(\"F1 score: %.2f%%\" % (f1 * 100))\n",
        "    print(\"-\" * 75)\n",
        "    print(\"\\n\\n\")"
      ],
      "metadata": {
        "id": "-TpRtutLjCg7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model(model, test_dataloader, title, model_load_path=\"./saved_model\"):\n",
        "\n",
        "  print(\"Testing model performance for the entire test dataset: \")\n",
        "  # Loads test dataset images\n",
        "  test_iterator = iter(test_dataloader)\n",
        "  inputs, labels = test_iterator.next()\n",
        "  inputs = inputs.to(device)\n",
        "  labels = labels.to(device)\n",
        "\n",
        "  # Loads saved model\n",
        "  model.load_state_dict(torch.load(model_load_path))\n",
        "  model.to(device)\n",
        "\n",
        "  # Gets model outputs\n",
        "  model.eval()\n",
        "  outputs = model(inputs)\n",
        "  _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "  preds = predicted.to(torch.device(\"cpu\")).numpy()\n",
        "  targets = labels.to(torch.device(\"cpu\")).numpy()\n",
        "\n",
        "  print_classification_report(preds, targets, title)\n",
        "\n",
        "  # matrix = confusion_matrix(targets, preds)\n",
        "  # print(matrix)\n",
        "\n",
        "  report = classification_report(targets, preds, target_names=[\"0_cloth\", \"1_surgical\", \"2_n95\", \"3_incorrect\", \"4_no_mask\"])\n",
        "  print(report) "
      ],
      "metadata": {
        "id": "IBdAwOKTaVqC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Defines a function for using the model for single input prediction (application mode). This function only considers the final CNN architecture. It does not consider the variant models."
      ],
      "metadata": {
        "id": "EJxcCLrNcac0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def single_prediction(image, model_load_path=\"./saved_model\"):\n",
        "\n",
        "  label_to_class = {0: '1_cloth_mask', 1: '2_surgical', 2: '3_n95', 3: '4_incorrect_mask', 4: '5_no_mask'}\n",
        "  preprocess_transform = transforms.Compose(\n",
        "                   [transforms.Resize((32,32)),\n",
        "                    transforms.ToTensor(),\n",
        "                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "  image_tensor = preprocess_transform(image).float()\n",
        "  image_tensor = image_tensor.unsqueeze_(0)\n",
        "  input = Variable(image_tensor)\n",
        "  input = input.to(device)\n",
        "\n",
        "  # Loads saved model\n",
        "  loaded_model = StackedCNN()\n",
        "  loaded_model.load_state_dict(torch.load(model_load_path))\n",
        "\n",
        "  loaded_model.to(device)\n",
        "  # Gets model outputs\n",
        "  loaded_model.eval()\n",
        "\n",
        "  output = loaded_model(input)\n",
        "  _, prediction = torch.max(output, 1)\n",
        "\n",
        "  return \"Classification: \" + label_to_class[prediction.item()]"
      ],
      "metadata": {
        "id": "ozY9ksTQcZiO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Defines setup for experiments:\n",
        "Defines variables for the model, hyperparameters, Classification Cross-Entropy loss and SGD with momentum"
      ],
      "metadata": {
        "id": "nQ1gYN-Qjw6f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Please uncomment and use the models as required.\n",
        "\"\"\"\n",
        "\n",
        "# Final CNN architecture for the project\n",
        "model = StackedCNN()\n",
        "model_name = \"stacked_cnn\"\n",
        "model_save_dir = \"./stacked_cnn\"\n",
        "\n",
        "# Variant 1\n",
        "# model = StackedCNNv1()\n",
        "# model_name = \"variant_1\"\n",
        "# model_save_dir = \"./variant_1\"\n",
        "\n",
        "# Variant 2\n",
        "# model = StackedCNNv2()\n",
        "# model_name = \"variant_2\"\n",
        "# model_save_dir = \"./variant_2\"\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "# Sets hyperparameter values\n",
        "num_epoch = 150\n",
        "\n",
        "class_samples = [445, 599, 209, 706, 641]\n",
        "class_weights = [1 - (x / sum(class_samples)) for x in class_samples]\n",
        "class_weights = torch.FloatTensor(class_weights).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "iDAaEQvYjrjv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. Runs experiments"
      ],
      "metadata": {
        "id": "t8ZdwdqVeYCI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loads dataset and splits into training, validation, and testing dataset\n",
        "train_dataloader, valid_dataloader, test_dataloader, label_to_class = project_data_loader()\n",
        "\n",
        "# Trains and saves the model\n",
        "saved_model_path = train_model(train_dataloader, valid_dataloader, model, criterion, optimizer, num_epoch=num_epoch, title=model_name, save_dir=model_save_dir)\n",
        "\n",
        "# Loads saved model and tests the performance using test dataset\n",
        "test_model(model, test_dataloader, title=model_name, model_load_path=saved_model_path)\n",
        "print(\"Testing completed.\")\n",
        "print(\"-\" * 75)\n",
        "\n",
        "# Loads saved model and performs prediction for single input for 5 samples\n",
        "print(\"Executing single input predition for 5 sample images.\")\n",
        "SINGLE_INPUT_DATA = \"./app_mode_samples\"\n",
        "sample_inputs = [join(SINGLE_INPUT_DATA, f) for f in listdir(SINGLE_INPUT_DATA) if isfile(join(SINGLE_INPUT_DATA, f))]\n",
        "for sample_input in sample_inputs:\n",
        "  with Image.open(sample_input) as image:\n",
        "    plt.figure()\n",
        "    plt.imshow(np.asarray(image))\n",
        "    plt.title(single_prediction(image))\n"
      ],
      "metadata": {
        "id": "NFx7NF-8ebwa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}